{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports and loading of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "from ruins.processing import drain_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load primary data\n",
    "data = xr.load_dataset('../data/hydro_krummh.nc').to_dataframe()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cached events\n",
    "with open('cache/events.pkl', 'rb') as file:\n",
    "    events = pickle.load(file)\n",
    "with open('cache/canals.pkl', 'rb') as file:\n",
    "    canal_par = pickle.load(file)\n",
    "with open('cache/pump.pkl', 'rb') as file:\n",
    "    pumpcap_fit = pickle.load(file)\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataframe with all events to be simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for RCP in ['rcp26','rcp45','rcp85', 'ref']:\n",
    "    print(RCP)\n",
    "    for ClimateTime in ['2065']:\n",
    "        if RCP == 'rcp26':\n",
    "            if ClimateTime == '2010':\n",
    "                SLRs = [35,122,221]  # SLR in 2030 SSP126, outer range of low/medium confidence\n",
    "                prec_increases = [0.9, 1, 1.1]\n",
    "            if ClimateTime == '2065':\n",
    "                SLRs = [154, 432, 848] # SLR in 2090 SSP126, outer range of low/medium confidence\n",
    "                prec_increases = [0.8, 0.9, 1, 1.1, 1.2]\n",
    "            comb26 = list(itertools.product(\n",
    "                            ['rcp26'],\n",
    "                              SLRs,\n",
    "                              prec_increases,\n",
    "                              events,\n",
    "                              [str(r) for r in canal_par],\n",
    "                              [4,6],\n",
    "                              [0,50,200],\n",
    "                              [1,4500,6000],\n",
    "                              data.filter(regex='Prec').columns,\n",
    "                              [np.nan],\n",
    "                              [np.nan]\n",
    "                             )\n",
    "                        )\n",
    "            \n",
    "        if RCP == 'ref':\n",
    "            if ClimateTime == '2010':\n",
    "                SLRs = [0]  # SLR in 2030 SSP126, outer range of low/medium confidence\n",
    "                prec_increases = [0.9, 1, 1.1]\n",
    "            if ClimateTime == '2065':\n",
    "                SLRs = [0] # SLR in 2090 SSP126, outer range of low/medium confidence\n",
    "                prec_increases = [0.8, 0.9, 1, 1.1, 1.2]\n",
    "            combref = list(itertools.product(\n",
    "                            ['ref'],\n",
    "                              SLRs,\n",
    "                              prec_increases,\n",
    "                              events,\n",
    "                              [str(r) for r in canal_par],\n",
    "                              [4,6],\n",
    "                              [0,50,200],\n",
    "                              [1,4500,6000],\n",
    "                              data.filter(regex='Prec').columns,\n",
    "                              [np.nan],\n",
    "                              [np.nan]\n",
    "                             )\n",
    "                            )\n",
    "\n",
    "        if RCP == 'rcp45':\n",
    "            if ClimateTime == '2010':\n",
    "                SLRs = [29,126,232]  # SLR in 2030 SSP245\n",
    "                prec_increases = [0.9, 1, 1.1]\n",
    "            if ClimateTime == '2065':\n",
    "                SLRs = [249, 522, 918] # SLR in 2090 SSP245\n",
    "                prec_increases = [0.8, 0.9, 1, 1.1, 1.2]\n",
    "\n",
    "                comb45 = list(itertools.product(\n",
    "                            ['rcp45'],\n",
    "                              SLRs,\n",
    "                              prec_increases,\n",
    "                              events,\n",
    "                              [str(r) for r in canal_par],\n",
    "                              [4,6],\n",
    "                              [0,50,200],\n",
    "                              [1,4500,6000],\n",
    "                              data.filter(regex='Prec').columns,\n",
    "                              [np.nan],\n",
    "                              [np.nan]\n",
    "                             )\n",
    "                        )\n",
    "        if RCP == 'rcp85':\n",
    "            if ClimateTime == '2010':\n",
    "                SLRs = [34,125,231]  # SLR in 2030 SSP126, outer range of low/medium confidence\n",
    "                prec_increases = [0.9, 1, 1.1]\n",
    "            if ClimateTime == '2065':\n",
    "                SLRs = [379, 730, 1143, 1676] # SLR in 2090 SSP126, lower range of low/medium confidence, upper range: 1143 for medium confidence,1676 for low confidence \n",
    "                prec_increases = [0.8, 0.9, 1, 1.1, 1.2, 1.3]\n",
    "        \n",
    "        \n",
    "            comb85 = list(itertools.product(\n",
    "                            ['rcp85'],\n",
    "                              SLRs,\n",
    "                              prec_increases,\n",
    "                              events,\n",
    "                              [str(r) for r in canal_par],\n",
    "                              [4,6],\n",
    "                              [0,50,200],\n",
    "                              [1,4500,6000],\n",
    "                              data.filter(regex='Prec').columns\n",
    "                            )\n",
    "                         )\n",
    "\n",
    "#print(len(comb26)+len(comb45)+len(comb85)+len(combref))\n",
    "#comb26[0:2]\n",
    "\n",
    "comb26.extend(comb45)\n",
    "comb26.extend(comb85)\n",
    "comb26.extend(combref)\n",
    "print(len(comb26))\n",
    "\n",
    "combis = pd.DataFrame(comb26, columns= ['rcp','SLR','prec_incr',\n",
    "                                        'event','canal_para', 'canal_area',\n",
    "                                        'forecast_pump', 'maxdh','raindissagg',\n",
    "                                        'max_store','energy_cons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do simulations - parallel processing would be nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for index, row in combis.iterrows():\n",
    "    if (i%5000 == 0):\n",
    "        print(i)\n",
    "        print(datetime.datetime.now())\n",
    "    t1 = events[row.event]\n",
    "    t2 = events[row.event]+datetime.timedelta(days=14)\n",
    "    hourly_recharge = data[row.raindissagg][t1:t2]\n",
    "    days = (t2-t1).days\n",
    "    hours = days*24 + 1\n",
    "    tide = data['wl_Knock_Outer'][t1:t2] + row.SLR     # add SLR to tide water level [mm]\n",
    "    hourly_recharge = hourly_recharge.rolling(\"12h\").mean() # smoothen rainfall signal to account for water redistribution within catchment\n",
    "    hourly_recharge *= row.prec_incr  # scale hourly recharge by change in climate forcing\n",
    "    wig = tide*0     # no wind induced gradient -> this may be used to simulate a local flooding in a subcatchment\n",
    "    x = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            'recharge' : hourly_recharge.fillna(0),\n",
    "            'h_tide' : tide.fillna(100),\n",
    "            'wig' : wig.fillna(0),\n",
    "        }\n",
    "    )\n",
    "    canal_para= tuple(float(v.lstrip(\"('\").rstrip(\"')\")) for v in row.canal_para.split(\", \"))\n",
    "    x['h_store'], q_pump, x['h_min'], x['flow_rec'], pump_cost, x['store'] = drain_cap.storage_model(\n",
    "        forcing_data = x,\n",
    "        canal_par = canal_para,\n",
    "        v_store = 0,\n",
    "        h_store_target = -1350,\n",
    "        canal_area = row.canal_area,\n",
    "        h_forecast_pump = row.forecast_pump,\n",
    "        h_grad_pump_max = row.maxdh,\n",
    "        pump_par = pumpcap_fit)\n",
    "    combis.loc[index,'max_store'] = max(x['store'])\n",
    "    combis.loc[index,'energy_cons'] = sum(pump_cost)\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combis.to_csv(\"res_final.csv\")\n",
    "#results = pd.read_csv(\"res_final.csv\", index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
